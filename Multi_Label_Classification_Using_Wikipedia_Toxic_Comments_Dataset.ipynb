{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multi-Label Classification Using Wikipedia Toxic Comments Dataset.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "h9q89SGLejdQ",
        "6lWFdG2uejgL"
      ],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hamxea/Multi-label-Classification/blob/master/Multi_Label_Classification_Using_Wikipedia_Toxic_Comments_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "JnB0s1tPejbl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Multi-Label Text Classification of Text Documnet or News\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "fKccKTR_ejbm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " ### DATASET\n",
        "\n",
        "Toxic Comment Classification dataset. a multi-label text classfication data consisting of many wikipedia comments which have been labeled by humans according to their relative toxicity comments labels such as \"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", and  \"identity_hate\". The dataset has approximately ~160k observation in total, ~125k with zero labels (toxicity) of any type, and approximately ~35k classified in one or more toxicity categories.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "h4oWa1Aqejbn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### DATA CHARACTERISTICS (TRAIN DATASET)\n",
        "* Number of data points\t159571\n",
        "* Number data points of type toxic\t15294\n",
        "* Number data points of type severe_tocic\t1595\n",
        "* Number data points of type obscene\t8449\n",
        "* Number data points of type threat\t478\n",
        "* Number data points of type insult\t7877\n",
        "* Number data points of type identity_hate\t1405\n",
        "* Observations in one or more class\t35098\n",
        "* Unclassified observation\t124473\n"
      ]
    },
    {
      "metadata": {
        "id": "NoB57aB6ejbo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Import necessary libraries for the experiment"
      ]
    },
    {
      "metadata": {
        "id": "BXuDj-0Vejbp",
        "colab_type": "code",
        "outputId": "f422b4bc-243f-40ab-d278-f681bab866a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "# importing libraries\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing import text, sequence\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers\n",
        "from keras.models import Model, Input, Sequential\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, SpatialDropout1D, Activation\n",
        "from keras.layers import Conv1D, Bidirectional, GlobalMaxPool1D, MaxPooling1D, BatchNormalization\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils.vis_utils import plot_model\n",
        "\n",
        "# For custom metrics\n",
        "import keras.backend as K\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        " \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.style.use('seaborn')\n",
        "\n",
        "import seaborn as sns\n",
        "from IPython.display import Image\n",
        "\n",
        "from tqdm import tqdm\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import RegexpTokenizer \n",
        "import os, re, csv, math, codecs\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "np.random.seed(0)\n",
        "\n",
        "DATA_PATH = '../input/'\n",
        "EMBEDDING_DIR = '../input/'\n",
        "\n",
        "\n",
        "# Install dependencies\n",
        "!apt install graphviz\n",
        "!pip install pydot pydot-ng\n",
        "!echo \"Double check with Python 3\"\n",
        "!python -c \"import pydot\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "graphviz is already the newest version (2.40.1-2).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-410\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 11 not upgraded.\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.6/dist-packages (1.3.0)\n",
            "Requirement already satisfied: pydot-ng in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.6/dist-packages (from pydot) (2.4.0)\n",
            "Double check with Python 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Wbd_vQHxejbu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Loading the necessary data files and data Preparation"
      ]
    },
    {
      "metadata": {
        "id": "rnEYH-JRfHyY",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "57a4ce55-fbfd-470f-dc17-b70b11c8761b"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6df9b874-ef14-4fd6-8417-a39a51c8541c\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-6df9b874-ef14-4fd6-8417-a39a51c8541c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving wiki.simple.vec to wiki.simple.vec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DO9qHBCkejbw",
        "colab_type": "code",
        "outputId": "e43a60eb-3ab8-44fa-9f23-58bfa737b26b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        }
      },
      "cell_type": "code",
      "source": [
        "#Train data\n",
        "train = pd.read_csv('train.csv')\n",
        "train.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-16dbaff9f5b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "bThKgInKejb0",
        "colab_type": "code",
        "outputId": "0613d5cd-ff10-4200-e839-f244f81ddc41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "cell_type": "code",
      "source": [
        "#Test data\n",
        "df_test = pd.read_csv('test.csv')\n",
        "df_test.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00001cee341fdb12</td>\n",
              "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0000247867823ef7</td>\n",
              "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00013b17ad220c46</td>\n",
              "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00017563c3f7919a</td>\n",
              "      <td>:If you have a look back at the source, the in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00017695ad8997eb</td>\n",
              "      <td>I don't anonymously edit articles at all.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0001ea8717f6de06</td>\n",
              "      <td>Thank you for understanding. I think very high...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>00024115d4cbde0f</td>\n",
              "      <td>Please do not add nonsense to Wikipedia. Such ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>000247e83dcc1211</td>\n",
              "      <td>:Dear god this site is horrible.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>00025358d4737918</td>\n",
              "      <td>\" \\n Only a fool can believe in such numbers. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>00026d1092fe71cc</td>\n",
              "      <td>== Double Redirects == \\n\\n When fixing double...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id                                       comment_text\n",
              "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...\n",
              "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...\n",
              "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n",
              "3  00017563c3f7919a  :If you have a look back at the source, the in...\n",
              "4  00017695ad8997eb          I don't anonymously edit articles at all.\n",
              "5  0001ea8717f6de06  Thank you for understanding. I think very high...\n",
              "6  00024115d4cbde0f  Please do not add nonsense to Wikipedia. Such ...\n",
              "7  000247e83dcc1211                   :Dear god this site is horrible.\n",
              "8  00025358d4737918  \" \\n Only a fool can believe in such numbers. ...\n",
              "9  00026d1092fe71cc  == Double Redirects == \\n\\n When fixing double..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "PAj6D9IZejb5",
        "colab_type": "code",
        "outputId": "c1123f0a-c8de-4dcc-bf71-0318112c682c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "cell_type": "code",
      "source": [
        "df_test_labels = pd.read_csv('test_labels.csv')\n",
        "\n",
        "df_test_labels.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00001cee341fdb12</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0000247867823ef7</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00013b17ad220c46</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00017563c3f7919a</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00017695ad8997eb</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0001ea8717f6de06</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>00024115d4cbde0f</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>000247e83dcc1211</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>00025358d4737918</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>00026d1092fe71cc</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  toxic  severe_toxic  obscene  threat  insult  \\\n",
              "0  00001cee341fdb12     -1            -1       -1      -1      -1   \n",
              "1  0000247867823ef7     -1            -1       -1      -1      -1   \n",
              "2  00013b17ad220c46     -1            -1       -1      -1      -1   \n",
              "3  00017563c3f7919a     -1            -1       -1      -1      -1   \n",
              "4  00017695ad8997eb     -1            -1       -1      -1      -1   \n",
              "5  0001ea8717f6de06      0             0        0       0       0   \n",
              "6  00024115d4cbde0f     -1            -1       -1      -1      -1   \n",
              "7  000247e83dcc1211      0             0        0       0       0   \n",
              "8  00025358d4737918     -1            -1       -1      -1      -1   \n",
              "9  00026d1092fe71cc     -1            -1       -1      -1      -1   \n",
              "\n",
              "   identity_hate  \n",
              "0             -1  \n",
              "1             -1  \n",
              "2             -1  \n",
              "3             -1  \n",
              "4             -1  \n",
              "5              0  \n",
              "6             -1  \n",
              "7              0  \n",
              "8             -1  \n",
              "9             -1  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "wB71FX4Lejb_",
        "colab_type": "code",
        "outputId": "c2d038d6-7b7f-4a05-c6ae-03a7bf0ff22f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "cell_type": "code",
      "source": [
        "test_labels = df_test_labels[(df_test_labels[['toxic','severe_toxic', 'obscene', 'threat', \n",
        "                                        'insult', 'identity_hate']] != -1).all(axis=1)]\n",
        "test_labels.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0001ea8717f6de06</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>000247e83dcc1211</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0002f87b16116a7f</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0003e1cccfd5a40a</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>00059ace3e3e9a53</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>000663aff0fffc80</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>000689dd34e20979</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>000844b52dee5f3f</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>00091c35fa9d0465</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>000968ce11f5ee34</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  id  toxic  severe_toxic  obscene  threat  insult  \\\n",
              "5   0001ea8717f6de06      0             0        0       0       0   \n",
              "7   000247e83dcc1211      0             0        0       0       0   \n",
              "11  0002f87b16116a7f      0             0        0       0       0   \n",
              "13  0003e1cccfd5a40a      0             0        0       0       0   \n",
              "14  00059ace3e3e9a53      0             0        0       0       0   \n",
              "16  000663aff0fffc80      0             0        0       0       0   \n",
              "17  000689dd34e20979      0             0        0       0       0   \n",
              "19  000844b52dee5f3f      0             0        0       0       0   \n",
              "21  00091c35fa9d0465      1             0        0       0       0   \n",
              "22  000968ce11f5ee34      0             0        0       0       0   \n",
              "\n",
              "    identity_hate  \n",
              "5               0  \n",
              "7               0  \n",
              "11              0  \n",
              "13              0  \n",
              "14              0  \n",
              "16              0  \n",
              "17              0  \n",
              "19              0  \n",
              "21              0  \n",
              "22              0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "Z4WMHSsEejcF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Merge the df_test and test_labels into 1 dataframe (test)"
      ]
    },
    {
      "metadata": {
        "id": "IN1JvMJxejcH",
        "colab_type": "code",
        "outputId": "ad1d9631-6dc9-4209-b47b-293606f45bc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "cell_type": "code",
      "source": [
        "#Merge the df_test and test_labels into 1 dataframe (test)\n",
        "test = pd.merge(test_labels, df_test, on='id', how='inner')\n",
        "test.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "      <th>comment_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0001ea8717f6de06</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Thank you for understanding. I think very high...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000247e83dcc1211</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>:Dear god this site is horrible.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0002f87b16116a7f</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>\"::: Somebody will invariably try to add Relig...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0003e1cccfd5a40a</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>\" \\n\\n It says it right there that it IS a typ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00059ace3e3e9a53</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>\" \\n\\n == Before adding a new product to the l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>000663aff0fffc80</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>this other one from 1897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>000689dd34e20979</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>== Reason for banning throwing == \\n\\n This ar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>000844b52dee5f3f</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>|blocked]] from editing Wikipedia.   |</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>00091c35fa9d0465</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>== Arabs are committing genocide in Iraq, but ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>000968ce11f5ee34</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Please stop. If you continue to vandalize Wiki...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  toxic  severe_toxic  obscene  threat  insult  \\\n",
              "0  0001ea8717f6de06      0             0        0       0       0   \n",
              "1  000247e83dcc1211      0             0        0       0       0   \n",
              "2  0002f87b16116a7f      0             0        0       0       0   \n",
              "3  0003e1cccfd5a40a      0             0        0       0       0   \n",
              "4  00059ace3e3e9a53      0             0        0       0       0   \n",
              "5  000663aff0fffc80      0             0        0       0       0   \n",
              "6  000689dd34e20979      0             0        0       0       0   \n",
              "7  000844b52dee5f3f      0             0        0       0       0   \n",
              "8  00091c35fa9d0465      1             0        0       0       0   \n",
              "9  000968ce11f5ee34      0             0        0       0       0   \n",
              "\n",
              "   identity_hate                                       comment_text  \n",
              "0              0  Thank you for understanding. I think very high...  \n",
              "1              0                   :Dear god this site is horrible.  \n",
              "2              0  \"::: Somebody will invariably try to add Relig...  \n",
              "3              0  \" \\n\\n It says it right there that it IS a typ...  \n",
              "4              0  \" \\n\\n == Before adding a new product to the l...  \n",
              "5              0                           this other one from 1897  \n",
              "6              0  == Reason for banning throwing == \\n\\n This ar...  \n",
              "7              0             |blocked]] from editing Wikipedia.   |  \n",
              "8              0  == Arabs are committing genocide in Iraq, but ...  \n",
              "9              0  Please stop. If you continue to vandalize Wiki...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "yMHnqLRhejcO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### No of records in the train and test data"
      ]
    },
    {
      "metadata": {
        "id": "N0shTlrPejcQ",
        "colab_type": "code",
        "outputId": "4498525b-b03e-4fc2-d13c-15bf0e7699e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Train data shape\", train.shape)\n",
        "print(\"Test data shape\", test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train data shape (159571, 8)\n",
            "Test data shape (63978, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dl8sCOPEejcX",
        "colab_type": "code",
        "outputId": "cf2a2475-bb05-4a15-f177-9ceaece70a51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "# check that there are no missing values in either training set\n",
        "print('The dataset has', train.isna().sum().sum(), 'missing values in train data.')\n",
        "print('The dataset has', test.isna().sum().sum(), 'missing values in test data.')\n",
        "\n",
        "# check if there are any duplicates\n",
        "print('The dataset has', train.duplicated().sum(), 'duplicates in train data.')\n",
        "print('The dataset has', test.duplicated().sum(), 'duplicates in test data.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The dataset has 0 missing values in train data.\n",
            "The dataset has 0 missing values in test data.\n",
            "The dataset has 0 duplicates in train data.\n",
            "The dataset has 0 duplicates in test data.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OcndCtd4ejcj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### CORRELATION BETWEEN DATA LABELS"
      ]
    },
    {
      "metadata": {
        "id": "xYT_uhvEejcl",
        "colab_type": "code",
        "outputId": "353ee9b6-85fc-4851-eed4-27cc9a991f32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        }
      },
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "fig.suptitle('Correlation Matrix')\n",
        "sns.heatmap(train.corr(), annot=True, cmap=\"Greens\", linewidths=.5, ax=ax);"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl8AAAGRCAYAAABbtdZEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQggTkuRLCCGEEMKEJPkSQgghhDCh/wdsr9B6jhcdpgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "4MQuxIYfejcq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The correlation figure below shows that Toxic\" comments are clearly correlated with both \"obscene\" and \"insult\" comments. Interestingly, \"toxic\" and \"severe_toxic\" are only weakly correlated. While we can also observe that, \"Obscene\" comments and \"insult\" comments are also highly correlated, which makes perfect sense."
      ]
    },
    {
      "metadata": {
        "id": "FHcTJeqwejcr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### DATA PREPROCESSING\n",
        "Deep Neural Networks input layers make use of input variables to feed the network for training the model. But in this task (experiment), we're dealing with words text. How do we represent these words in order to feed our model?\n",
        "\n",
        "In our experiment, we used densed representation of those text (comments) and their semanticity together. The advantage of using this approach is the best way for fitting neural networks onto a text data (as in our case), as well as less memory usage compared to other sparse representation approaches.\n",
        "\n",
        "\n",
        "#### Word Embedding\n",
        "Two ways to feed embeddings to neural networks:\n",
        "   * Using your own word embeddings by training\n",
        "   * Using pre-trained embedding (e.g Word2vec, lad2vec, Glove etc)\n",
        "   \n"
      ]
    },
    {
      "metadata": {
        "id": "LL_5zSxjejcs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Convert text to vectors using keras preprocessing library tools\n",
        "\n",
        "X_train = train[\"comment_text\"].values\n",
        "X_test  = test[\"comment_text\"].values\n",
        "\n",
        "y_train = train[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]].values\n",
        "y_test  = test[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uwqi-osSejcv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "For the first embedding, we used keras preprocessing (Text Preprocessing) libraries. This class allows to vectorize a text corpus, by turning each text into either a sequence of integers (each integer being the index of a token in a dictionary) or into a vector where the coefficient for each token could be binary, based on word count, based on tf-idf"
      ]
    },
    {
      "metadata": {
        "id": "cTMhD2dpejcw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_words = 20000 #Max. workds to use per toxic comment\n",
        "max_features = 200000 #Max. number of unique words in embeddinbg vector\n",
        "max_len = 200 #Max. number of words per toxic comment to be use\n",
        "embedding_dims = 128 #embedding vector output dimension \n",
        "num_epochs = 6 # (before 5)number of epochs (number of times that the model is exposed to the training dataset)\n",
        "val_split = 0.1\n",
        "batch_size2 = 32 #(before 32)The **batch size** is the number of training examples in one forward/backward pass. In general, larger batch sizes result in faster progress in training, but don't always converge as quickly. Smaller batch sizes train slower, but can converge faster. And the higher the batch size, the more memory space you’ll need."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H0rNWt-8ejcz",
        "colab_type": "code",
        "outputId": "346e5533-8ec9-4fd3-cc7c-b13bb16271fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "#toxic comments Tokenization\n",
        "tokenizer = tokenizer = Tokenizer(num_words)\n",
        "tokenizer.fit_on_texts(list(X_train))\n",
        "\n",
        "#Convert tokenized toxic commnent to sequnces\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "# padding the sequences\n",
        "X_train = sequence.pad_sequences(X_train, max_len)\n",
        "X_test  = sequence.pad_sequences(X_test,  max_len)\n",
        "\n",
        "print('X_train shape:', X_train.shape)\n",
        "print('X_test shape: ', X_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train shape: (159571, 200)\n",
            "X_test shape:  (63978, 200)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "h9q89SGLejdQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Train, Validation, Test Splits\n",
        "#### Train Data: \n",
        "The sample data used to fit the model.\n",
        "#### Validation Data: \n",
        "The sample of data used to provide an unbiased evaluation of a model fit on the training dataset while tuning model hyperparameters.\n",
        "\n",
        "#### Test Data:\n",
        "The sample of data used to provide an unbiased evaluation of a final model fit on the training dataset\n",
        "\n",
        "The test set is generally what is used to evaluate competing models (For example on many Kaggle competitions, the validation set is released initially along with the training set and the actual test set is only released when the competition is about to close, and it is the result of the the model on the Test set that decides the winner).\n",
        "\n",
        "\n",
        "#### Our Experiment Splits Ratio\n",
        "Split ratio on most of the experimental datasets depends mainly on two (2) things: The number of samples in the data, and the actual model you are training.\n",
        "\n",
        "It's always good to splits in the raio of (60%:20%:20%) in terms of (Train:Validation:Test) when you have 1 dataset. But thanks to kaggle competition spits of Train dataset and Test dataset. Now, we need to compute only the validation accuracy.\n",
        "\n",
        "\n",
        "In our experiment, we keep aside the Test set dataset, and used keras \"validation_split\" function in order to choose 80% of the Train dataset to be the actual Train set and the remaining (20%) to be the Validation set. The model is then iteratively trained and validated on these different sets.\n",
        "\n",
        "The Train dataset consists of (159571 samples), so when to split it into train and validaton. we have train split (0.8 of train dataset) =  127657  samples, while the validation split(0.2 of Train dataset) = 31914 samples. \n",
        "\n",
        "Lastly, the test dataset consists of 63930 samples, therefore, we use all the samples as our test split.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "ELlEnN6GejdS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## METHODS (NN, CNN, RNN, LSTM)"
      ]
    },
    {
      "metadata": {
        "id": "0evQXvGIx-Zg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### We used early callback functionality that allows you to specify the performance measure to monitor, the trigger, and once triggered. It will stop the training process."
      ]
    },
    {
      "metadata": {
        "id": "OAe9eO3YyOO-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6IYxIpKKejdU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1) Neural Network (NN)"
      ]
    },
    {
      "metadata": {
        "id": "ZfS1bFmuejdX",
        "colab_type": "code",
        "outputId": "cade3bff-051d-4a57-a3b8-c639a2388348",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "cell_type": "code",
      "source": [
        "nn_model = Sequential([\n",
        "    Embedding(input_dim=max_features, input_length=max_len, output_dim=embedding_dims),\n",
        "    GlobalMaxPool1D(),\n",
        "    Dense(50, activation = 'relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(6, activation = 'sigmoid')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NmnhIwlZejdg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Compile the NN model"
      ]
    },
    {
      "metadata": {
        "id": "qRcp8LQlejdj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Customized the evaluation to analyse the model in terms of accuracy and mean value accuracy\n",
        "def mean_pred(y_true, y_pred):\n",
        "    return K.mean(y_pred)\n",
        "\n",
        "nn_model.compile(loss='binary_crossentropy', optimizer=Adam(0.01), metrics=['accuracy', mean_pred])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qo0IneLWejdp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Visualize the Orchestrated NN Architecture"
      ]
    },
    {
      "metadata": {
        "id": "iRCTXDsxejdr",
        "colab_type": "code",
        "outputId": "620a5f59-597d-42c1-c6ec-09c57211e896",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "cell_type": "code",
      "source": [
        "nn_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 200, 128)          25600000  \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 50)                6450      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 6)                 306       \n",
            "=================================================================\n",
            "Total params: 25,606,756\n",
            "Trainable params: 25,606,756\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gLy1Fblwejdw",
        "colab_type": "code",
        "outputId": "f2c9741d-ed1a-43c6-8f97-5e145cd184e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "cell_type": "code",
      "source": [
        "#plot the nn_model architecture\n",
        "\n",
        "plot_model(nn_model, to_file='nn_model_plot.png', show_shapes=True, show_layer_names=True)\n",
        "Image(retina=True, filename='nn_model_plot.png')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-537e556c415c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'nn_model_plot.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretina\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'nn_model_plot.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plot_model' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "MzBlQem0ejdy",
        "colab_type": "code",
        "outputId": "b6a33252-912f-459b-aa8c-528eadc50892",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "cell_type": "code",
      "source": [
        "nn_model_fit = nn_model.fit(X_train, y_train, batch_size=batch_size2, epochs=num_epochs, validation_split=val_split, callbacks=[early])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "Train on 143613 samples, validate on 15958 samples\n",
            "Epoch 1/6\n",
            "143613/143613 [==============================] - 99s 692us/step - loss: 0.0669 - acc: 0.9777 - mean_pred: 0.0377 - val_loss: 0.0640 - val_acc: 0.9765 - val_mean_pred: 0.0248\n",
            "Epoch 2/6\n",
            "143613/143613 [==============================] - 96s 669us/step - loss: 0.0552 - acc: 0.9798 - mean_pred: 0.0366 - val_loss: 0.0539 - val_acc: 0.9805 - val_mean_pred: 0.0345\n",
            "Epoch 3/6\n",
            "143613/143613 [==============================] - 96s 666us/step - loss: 0.0528 - acc: 0.9801 - mean_pred: 0.0366 - val_loss: 0.0578 - val_acc: 0.9793 - val_mean_pred: 0.0409\n",
            "Epoch 4/6\n",
            "143613/143613 [==============================] - 96s 667us/step - loss: 0.0514 - acc: 0.9804 - mean_pred: 0.0365 - val_loss: 0.0656 - val_acc: 0.9742 - val_mean_pred: 0.0468\n",
            "Epoch 5/6\n",
            " 31232/143613 [=====>........................] - ETA: 1:13 - loss: 0.0466 - acc: 0.9812 - mean_pred: 0.0364"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_IZIZxQ9ejd2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Evaluate the NN accuracy of our trained model"
      ]
    },
    {
      "metadata": {
        "id": "8ob3ye95ejd3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "nn_train_score = nn_model.evaluate(X_train, y_train, batch_size = batch_size2, verbose = 1)\n",
        "print('Train loss:', nn_train_score[0])\n",
        "print('Train accuracy:', nn_train_score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DcTJIXSiejd6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Evaluate the NN accuracy base on the test dataset"
      ]
    },
    {
      "metadata": {
        "id": "NbotTcnqejd7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "nn_test_score = nn_model.evaluate(X_test, y_test, batch_size=batch_size2, verbose=1)\n",
        "print('Test Loss:', nn_test_score[0])\n",
        "print('Test Accuracy:', nn_test_score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WOx9_GWQejeA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Predicting......\n",
        "print('Predicting....')\n",
        "y_pred = nn_model.predict(X_test,batch_size=batch_size2,verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yVXVp2HcejeN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Plot Training & Validation Accuracy with the Loss values of the NN Model"
      ]
    },
    {
      "metadata": {
        "id": "kLZaIqkhejeP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Plot training & validation accuracy values\n",
        "plt.plot(nn_model_fit.history['acc'])\n",
        "plt.plot(nn_model_fit.history['val_acc'])\n",
        "plt.title('Neural Network (NN) Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training Accuracy', 'Validation Accuracy'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(nn_model_fit.history['loss'])\n",
        "plt.plot(nn_model_fit.history['val_loss'])\n",
        "plt.title('Neural Network (NN) Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training Loss', 'Validation Loss'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fvld34vXejeX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2) Convolutional Neural Network (CNN)"
      ]
    },
    {
      "metadata": {
        "id": "xRZT995EejeY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "CNN_model = Sequential([\n",
        "    Embedding(input_dim=max_features, input_length=max_len, output_dim=embedding_dims),\n",
        "    SpatialDropout1D(0.5),\n",
        "    # ... 100 filters with a kernel size of 4 so that each convolution will consider a window of 4 word embeddings\n",
        "    Conv1D(filters=100, kernel_size=4, padding='same', activation='relu'),\n",
        "    #**batch normalization layer** normalizes the activations of the previous layer at each batch, \n",
        "    #i.e. applies a transformation that maintains the mean activation close to 0 and the activation standard deviation close to 1. \n",
        "    #It will be added after the activation function between a convolutional and a max-pooling layer.\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    GlobalMaxPool1D(),\n",
        "    Dense(50, activation = 'relu'),\n",
        "    Dense(6, activation = 'sigmoid')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8n2R1B4Hejee",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Customized the evaluation to analyse the model in terms of accuracy and mean value accuracy\n",
        "def mean_pred(y_true, y_pred):\n",
        "    return K.mean(y_pred)\n",
        "\n",
        "CNN_model.compile(loss='binary_crossentropy', optimizer=Adam(0.01), metrics=['accuracy', mean_pred])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KBKoKx_mejej",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Visualize the Orchestrated CNN MODEL Architecture"
      ]
    },
    {
      "metadata": {
        "id": "SUxPEGT5ejej",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "CNN_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cj5FJvhvejem",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#plot the CNN model architecture\n",
        "\n",
        "plot_model(CNN_model, to_file='CNN_model_plot.png', show_shapes=True, show_layer_names=True)\n",
        "Image(retina=True, filename='CNN_model_plot.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EyjGbmUfejeo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "CNN_model_fit = CNN_model.fit(X_train, y_train, batch_size=batch_size2, epochs=num_epochs, validation_split=val_split, callbacks=[early])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_lhGd1B0ejeq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Evaluate the CNN Model accuracy of our trained model"
      ]
    },
    {
      "metadata": {
        "id": "FNIsK00Wejer",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "CNN_train_score = CNN_model.evaluate(X_train, y_train, batch_size = batch_size2, verbose = 1)\n",
        "print('Train loss:', CNN_train_score[0])\n",
        "print('Train accuracy:', CNN_train_score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6HrWCm8weje2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Evaluate the CNN accuracy base our test samples"
      ]
    },
    {
      "metadata": {
        "id": "kDrULGFMeje4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "CNN_test_score = CNN_model.evaluate(X_test, y_test, batch_size=batch_size2, verbose=1)\n",
        "print('Test Loss:', CNN_test_score[0])\n",
        "print('Test Accuracy:', CNN_test_score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dafZW6vAeje9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Predicting......\n",
        "print('Predicting....')\n",
        "y_pred = CNN_model.predict(X_test,batch_size=batch_size2,verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DKRqMXsGejfG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Plot Training & Validation Accuracy with the Loss values of the CNN Model"
      ]
    },
    {
      "metadata": {
        "id": "9ZZ6Fk8rejfH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Plot training & validation accuracy values\n",
        "plt.plot(CNN_model_fit.history['acc'])\n",
        "plt.plot(CNN_model_fit.history['val_acc'])\n",
        "plt.title('Convolutional Neural Network (CNN) Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training Accuracy', 'Validation Accuracy'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(CNN_model_fit.history['loss'])\n",
        "plt.plot(CNN_model_fit.history['val_loss'])\n",
        "plt.title('Convolutional Neural Network (CNN) Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training Loss', 'Validation Loss'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "osfA6NdMejfP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3) Recurrent Neural Networks (RNNs)"
      ]
    },
    {
      "metadata": {
        "id": "qcEEfcEwejfR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "RNN_model = Sequential([\n",
        "    Embedding(input_dim=max_features, input_length=max_len, output_dim=embedding_dims),\n",
        "    SpatialDropout1D(0.5),\n",
        "    #Bidirectional layer will enable our model to predict a missing word in a sequence, \n",
        "    #So, using this feature will enable the model to look at the context on both the left and the right.\n",
        "    Bidirectional(LSTM(25, return_sequences=True)),\n",
        "    #**batch normalization layer** normalizes the activations of the previous layer at each batch, \n",
        "    #i.e. applies a transformation that maintains the mean activation close to 0 and the activation standard deviation close to 1. \n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    GlobalMaxPool1D(),\n",
        "    Dense(50, activation = 'relu'),\n",
        "    Dense(6, activation = 'sigmoid')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WWwi-7iEejfX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Customized the evaluation to analyse the model in terms of accuracy and mean value accuracy\n",
        "def mean_pred(y_true, y_pred):\n",
        "    return K.mean(y_pred)\n",
        "\n",
        "RNN_model.compile(loss='binary_crossentropy', optimizer=Adam(0.01), metrics=['accuracy', mean_pred])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-9NGy7Bxejfc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Visualize the Orchestrated RNN MODEL Architecture"
      ]
    },
    {
      "metadata": {
        "id": "ceRB6-Hpejfc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "RNN_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X-y2CvXWejfg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#plot the RNN model architecture\n",
        "\n",
        "plot_model(RNN_model, to_file='CNN_model_plot.png', show_shapes=True, show_layer_names=True)\n",
        "Image(retina=True, filename='CNN_model_plot.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kO0xUVQZejfi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "RNN_model_fit = RNN_model.fit(X_train, y_train, batch_size=batch_size2, epochs=num_epochs, validation_split=val_split, callbacks=[early])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9dV0mgtpejgA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Evaluate the RNN Model accuracy of our trained model"
      ]
    },
    {
      "metadata": {
        "id": "rVI6X2FoejgB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "RNN_train_score = RNN_model.evaluate(X_train, y_train, batch_size=batch_size2, verbose=1)\n",
        "print('Test Loss:', RNN_train_score[0])\n",
        "print('Test Accuracy:', RNN_train_score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pW5x9tccejgD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Evaluate the RNN accuracy base our test samples"
      ]
    },
    {
      "metadata": {
        "id": "TSVQVTrLejgE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "RNN_test_score = RNN_model.evaluate(X_test, y_test, batch_size=batch_size2, verbose=1)\n",
        "print('Test Loss:', RNN_test_score[0])\n",
        "print('Test Accuracy:', RNN_test_score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZlYMwKjMejgG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Plot Training & Validation Accuracy with the Loss values of the RNN Model"
      ]
    },
    {
      "metadata": {
        "id": "l88SHLD4ejgG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Plot training & validation accuracy values\n",
        "plt.plot(RNN_model_fit.history['acc'])\n",
        "plt.plot(RNN_model_fit.history['val_acc'])\n",
        "plt.title('Recurrent Neural Networks (RNNs) Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training Accuracy', 'Validation Accuracy'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(RNN_model_fit.history['loss'])\n",
        "plt.plot(RNN_model_fit.history['val_loss'])\n",
        "plt.title('Recurrent Neural Networks (RNNs) Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training Loss', 'Validation Loss'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6lWFdG2uejgL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### USING PRE-TRAINED EMBEDDING"
      ]
    },
    {
      "metadata": {
        "id": "BXJAQEogejgM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## A) \"Glove\" as a pre-trained Embedding"
      ]
    },
    {
      "metadata": {
        "id": "iSKIyBVbejgh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Prepare the pre-trained embedding layer"
      ]
    },
    {
      "metadata": {
        "id": "o2NVoopbejgj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Load glove embedding corpus"
      ]
    },
    {
      "metadata": {
        "id": "okYLw1HSejgk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "glove_file = open('glove.6B.100d.txt', encoding=\"utf8\")\n",
        "embeddings_index = dict()\n",
        "for line in glove_file:\n",
        "    val = line.split(' ')\n",
        "    word = val[0]\n",
        "    coefs = np.asarray(val[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "glove_file.close()\n",
        "\n",
        "print('Loaded %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OTAsNvo8ejgn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Prepare the embedding matrix vectors in order to feed/pass the neural network"
      ]
    },
    {
      "metadata": {
        "id": "GrtLyPSOejgo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create a weight matrix\n",
        "embedding_matrix = np.zeros((len(tokenizer.word_index)+1, 100))\n",
        "\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "esr3C21fejgr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 4) Convolutional Neural Network (CNN) with Glove"
      ]
    },
    {
      "metadata": {
        "id": "-WAtTqG_ejgs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "CNN_Glove_model = Sequential([\n",
        "    Embedding(input_dim =embedding_matrix.shape[0], input_length=max_len, output_dim=embedding_matrix.shape[1],weights=[embedding_matrix], trainable=False),\n",
        "    SpatialDropout1D(0.5),\n",
        "    # ... 100 filters with a kernel size of 4 so that each convolution will consider a window of 4 word embeddings\n",
        "    Conv1D(filters=100, kernel_size=4, padding='same', activation='relu'),\n",
        "    #**batch normalization layer** normalizes the activations of the previous layer at each batch, \n",
        "    #i.e. applies a transformation that maintains the mean activation close to 0 and the activation standard deviation close to 1. \n",
        "    #It will be added after the activation function between a convolutional and a max-pooling layer.\n",
        "    BatchNormalization(),\n",
        "    GlobalMaxPool1D(),\n",
        "    Dropout(0.5),\n",
        "    Dense(50, activation = 'relu'),\n",
        "    Dense(6, activation = 'sigmoid')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ax47pBijejgv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Customized the evaluation to analyse the model in terms of accuracy and mean value accuracy\n",
        "def mean_pred(y_true, y_pred):\n",
        "    return K.mean(y_pred)\n",
        "\n",
        "CNN_Glove_model.compile(loss='binary_crossentropy', optimizer=Adam(0.01), metrics=['accuracy', mean_pred])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5gNpZ61pejgz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Visualize the Orchestrated CNN-Glove Model Architecture"
      ]
    },
    {
      "metadata": {
        "id": "-ZCm_OM4ejg0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "CNN_Glove_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zvA_w6iZejg8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#plot the CNN_GLove model architecture\n",
        "\n",
        "plot_model(CNN_Glove_model, to_file='CNN_Glove_model_plot.png', show_shapes=True, show_layer_names=True)\n",
        "Image(retina=True, filename='CNN_Glove_model_plot.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QHt7nKCVejhE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "CNN_Glove_model_fit = CNN_Glove_model.fit(X_train, y_train, batch_size=batch_size2, epochs=num_epochs, validation_split=val_split, callbacks=[early])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "shJIVGXhejhQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Evaluate the CNN+Glove Model accuracy of our trained model"
      ]
    },
    {
      "metadata": {
        "id": "bByseHEkejhQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "CNN_Glove_train_score = CNN_Glove_model.evaluate(X_train, y_train, batch_size=batch_size2, verbose=1)\n",
        "print('Test Loss:', CNN_Glove_train_score[0])\n",
        "print('Test Accuracy:', CNN_Glove_train_score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dnD4FG1ZejhX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Evaluate the CNN+Glove accuracy base our test samples"
      ]
    },
    {
      "metadata": {
        "id": "TTM0ur18ejhZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "CNN_Glove_test_score = CNN_Glove_model.evaluate(X_test, y_test, batch_size=batch_size2, verbose=1)\n",
        "print('Test Loss:', CNN_Glove_test_score[0])\n",
        "print('Test Accuracy:', CNN_Glove_test_score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ATrgpBBTejhf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Predicting......\n",
        "print('Predicting....')\n",
        "y_pred = CNN_Glove_model.predict(X_test,batch_size=batch_size2,verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uwuQDaeIejhp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Plot Training & Validation Accuracy with the Loss values of the CNN-Glove Model"
      ]
    },
    {
      "metadata": {
        "id": "GcQfB3rIejhq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Plot training & validation accuracy values\n",
        "plt.plot(CNN_Glove_model_fit.history['acc'])\n",
        "plt.plot(CNN_Glove_model_fit.history['val_acc'])\n",
        "plt.title('CNN-Glove Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training Accuracy', 'Validation Accuracy'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(CNN_Glove_model_fit.history['loss'])\n",
        "plt.plot(CNN_Glove_model_fit.history['val_loss'])\n",
        "plt.title('CNN-Glove Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training Loss', 'Validation Loss'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VH5poTW6ejhv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 5) Recurrent Neural Network (RNN) with Glove"
      ]
    },
    {
      "metadata": {
        "id": "j-i4BwjTejhv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "RNN_Glove_model = Sequential([\n",
        "    Embedding(input_dim =embedding_matrix.shape[0], input_length=max_len, output_dim=embedding_matrix.shape[1],weights=[embedding_matrix], trainable=False),\n",
        "    SpatialDropout1D(0.5),\n",
        "    #Bidirectional layer will enable our model to predict a missing word in a sequence, \n",
        "    #So, using this feature will enable the model to look at the context on both the left and the right.\n",
        "    Bidirectional(LSTM(25, return_sequences=True)),\n",
        "    #**batch normalization layer** normalizes the activations of the previous layer at each batch, \n",
        "    #i.e. applies a transformation that maintains the mean activation close to 0 and the activation standard deviation close to 1. \n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    GlobalMaxPool1D(),\n",
        "    Dense(50, activation = 'relu'),\n",
        "    Dense(6, activation = 'sigmoid')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MdHhejTiejiG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Customized the evaluation to analyse the model in terms of accuracy and mean value accuracy\n",
        "def mean_pred(y_true, y_pred):\n",
        "    return K.mean(y_pred)\n",
        "\n",
        "RNN_Glove_model.compile(loss='binary_crossentropy', optimizer=Adam(0.01), metrics=['accuracy', mean_pred])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ceJvCqIJejiR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Visualize the Orchestrated RNN-Glove MODEL Architecture"
      ]
    },
    {
      "metadata": {
        "id": "JbUgJkaCejiS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "RNN_Glove_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Eon8HZtDejiV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#plot the RNN_GLove model architecture\n",
        "\n",
        "plot_model(RNN_Glove_model, to_file='RNN_Glove_model_plot.png', show_shapes=True, show_layer_names=True)\n",
        "Image(retina=True, filename='RNN_Glove_model_plot.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u1NlZQUoejib",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "RNN_Glove_model_fit = RNN_Glove_model.fit(X_train, y_train, batch_size=batch_size2, epochs=num_epochs, validation_split=val_split, callbacks=[early])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "78TSAA6Yejik",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Evaluate the RNN-Glove Model accuracy of our trained model"
      ]
    },
    {
      "metadata": {
        "id": "YnRgQoyXejil",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "RNN_Glove_train_score = RNN_Glove_model.evaluate(X_train, y_train, batch_size = batch_size2, verbose = 1)\n",
        "print('Train loss:', RNN_Glove_train_score[0])\n",
        "print('Train accuracy:', RNN_Glove_train_score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "niE14vnrejim",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Evaluate the RNN-Glove accuracy base our test samples"
      ]
    },
    {
      "metadata": {
        "id": "Cc5KDayqejin",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "RNN_Glove_test_score = RNN_Glove_model.evaluate(X_train, y_train, batch_size = batch_size2, verbose = 1)\n",
        "print('Train loss:', RNN_Glove_test_score[0])\n",
        "print('Train accuracy:', RNN_Glove_test_score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D71PCeroejio",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "italicized text### Plot Training & Validation Accuracy with the Loss values of the RNN-Glove Model"
      ]
    },
    {
      "metadata": {
        "id": "UUEbY28nejio",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Plot training & validation accuracy values\n",
        "plt.plot(RNN_Glove_model_fit.history['acc'])\n",
        "plt.plot(RNN_Glove_model_fit.history['val_acc'])\n",
        "plt.title('RNN-Glove Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training Accuracy', 'Validation Accuracy'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(RNN_Glove_model_fit.history['loss'])\n",
        "plt.plot(RNN_Glove_model_fit.history['val_loss'])\n",
        "plt.title('RNN-Glove Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training Loss', 'Validation Loss'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2SuIGRWehRwO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## B) \"Word2Vec\" as a pre-Trained Embedding"
      ]
    },
    {
      "metadata": {
        "id": "thDluqVPiOpm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Firstly, we separately learnt word embeddings and then pass to the embedding layer. This approach allows to use  pre-trained (Word2Vec) word embedding and also saves the time in training the classification model.\n",
        "\n",
        "In this part of experiment, we used Geness implementaion of Word2Vec."
      ]
    },
    {
      "metadata": {
        "id": "D9NglSpbiZao",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create the word tokens in order to prepare the Text corpus for leanring the embedding"
      ]
    },
    {
      "metadata": {
        "id": "q22sYHKGiddC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "toxicComments_lines = list()\n",
        "lines = train['comment_text'].values.tolist()\n",
        "\n",
        "for line in lines:\n",
        "    tokens = word_tokenize(line)\n",
        "    \n",
        "    #convert to lower case\n",
        "    tokens = [w.lower() for w in tokens]\n",
        "    \n",
        "    #remove punctuation from each word\n",
        "    table =  str.maketrans('', '', string.punctuation)\n",
        "    stripped = [w.translate(table) for w in tokens]\n",
        "    \n",
        "    #remove remaining tpkens gthat are not alphabetic\n",
        "    words = [word for word in stripped if word.isalpha()]\n",
        "    \n",
        "    #filter out stop words\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = [w for w in words if not w in stop_words]\n",
        "    toxicComments_lines.append(words)\n",
        "\n",
        "\n",
        "len(toxicComments_lines)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "unnnArHDihiL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Train the Word2Vec"
      ]
    },
    {
      "metadata": {
        "id": "usSFc7OmiobO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#train word2vec mode\n",
        "embedding_dims = 128 #embedding vector output dimension \n",
        "max_len = 200 #Max. number of words per toxic comment to be use\n",
        "word2VecModel = gensim.models.Word2Vec(sentences=toxicComments_lines, size= embedding_dims, window=5, workers=4, min_count=1)\n",
        "#vocab size\n",
        "wors = list(word2VecModel.wv.vocab)\n",
        "print('Vocabulary size: %d' % len(words))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SnIWOASsitYa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Test Word2Vec Model of the toxic comment corpus. We tried some word embeddings from the model learnt from the wikipedia toxic comment tran dataset"
      ]
    },
    {
      "metadata": {
        "id": "IcgwO8Wfisfm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "word2VecModel.wv.most_similar('shit')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iw62A32ki2D4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Let's see the reulst of semantically reasonable word vetors (king - man + woman)\n",
        "word2VecModel.wv.most_similar_cosmul(positive=['woman', 'king'], negative=['man'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nNH_fcpPi4ef",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Let us find the odd word woman, king, queen, movie = ?\n",
        "#add word out\n",
        "print(word2VecModel.wv.doesnt_match(\"woman king queen movie\".split()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WHgNZtRFi-Y2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Save the Word2Vec Corpus locally"
      ]
    },
    {
      "metadata": {
        "id": "v0c4qsY6i__S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#save model\n",
        "filename = 'toxic_embedding_word2vec.txt'\n",
        "word2VecModel.wv.save_word2vec_format(filename, binary=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P4obkfWHjM6Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Use the Pre-Trained Embedding (Word2Vec) in our models (CNN, and RNN)"
      ]
    },
    {
      "metadata": {
        "id": "aAtdEnVRjOgx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "word2Vec_embeddings_index = {}\n",
        "word2vec_file = open(os.path.join('', 'toxic_embedding_word2vec.txt'), encoding = \"utf-8\")\n",
        "\n",
        "for line in word2vec_file:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefficient = np.asarray(values[1:])\n",
        "    word2Vec_embeddings_index[word] = coefficient\n",
        "word2vec_file.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bI0rRFgZjT95",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Convert the word embedding into tokenized vector"
      ]
    },
    {
      "metadata": {
        "id": "vI-e9hy-jViP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#vectorize the text samples into a 2D integer tensor\n",
        "tokenizer_obj = Tokenizer()\n",
        "tokenizer_obj.fit_on_texts(toxicComments_lines)\n",
        "sequences = tokenizer_obj.texts_to_sequences(toxicComments_lines)\n",
        "\n",
        "#pad sequences\n",
        "word_index = tokenizer_obj.word_index\n",
        "print('Found %s uniquue tokens.' % len(word_index))\n",
        "\n",
        "toxicComments_pad = pad_sequences(sequences, maxlen=max_len)\n",
        "comments_tag = train[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]].values\n",
        "print('Shape of toxic comments tensor', toxicComments_pad.shape)\n",
        "print('Shape of comment tensor', comments_tag.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4JuiKGE2jdqF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### We mapped the embeddings from the loaded word2vec model so that each word to the tokenizer_obj.word_index vocabulary and create a matrix with of word vectors."
      ]
    },
    {
      "metadata": {
        "id": "Q8e9mWPQjfn4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_words = len(word_index)+1\n",
        "word2Vec_embedding_matrix = np.zeros((num_words, embedding_dims))\n",
        "\n",
        "for word, i  in word_index.items():\n",
        "    if i > num_words:\n",
        "        continue\n",
        "    word2Vec_embedding_vector = word2Vec_embeddings_index.get(word)\n",
        "    if word2Vec_embedding_vector is not None:\n",
        "        #words not found in embedding index will be all-zeros.\n",
        "        word2Vec_embedding_matrix[i] = word2Vec_embedding_vector\n",
        "\n",
        "print(num_words)\n",
        "print(word2Vec_embedding_matrix.shape[0])\n",
        "print(word2Vec_embedding_matrix.shape[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O5g3oMqWjk4P",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 6) Convolutional Neural Network (CNN) with Word2Vec"
      ]
    },
    {
      "metadata": {
        "id": "-4vRilk0jsGS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "CNN_Word2Vec_model = Sequential([\n",
        "    Embedding(input_dim =word2Vec_embedding_matrix.shape[0], input_length=max_len, output_dim=word2Vec_embedding_matrix.shape[1],weights=[word2Vec_embedding_matrix], trainable=False),\n",
        "    SpatialDropout1D(0.5),\n",
        "    # ... 100 filters with a kernel size of 4 so that each convolution will consider a window of 4 word embeddings\n",
        "    Conv1D(filters=100, kernel_size=4, padding='same', activation='relu'),\n",
        "    #**batch normalization layer** normalizes the activations of the previous layer at each batch, \n",
        "    #i.e. applies a transformation that maintains the mean activation close to 0 and the activation standard deviation close to 1. \n",
        "    #It will be added after the activation function between a convolutional and a max-pooling layer.\n",
        "    BatchNormalization(),\n",
        "    GlobalMaxPool1D(),\n",
        "    Dropout(0.5),\n",
        "    Dense(50, activation = 'relu'),\n",
        "    Dense(6, activation = 'sigmoid')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ufAM3SM4jw9D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Customized the evaluation to analyse the model in terms of accuracy and mean value accuracy\n",
        "def mean_pred(y_true, y_pred):\n",
        "    return K.mean(y_pred)\n",
        "\n",
        "CNN_Word2Vec_model.compile(loss='binary_crossentropy', optimizer=Adam(0.01), metrics=['accuracy', mean_pred])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "enZRJY0HjzGs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "CNN_Word2Vec_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6QMA1u6lwOC_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#plot the CNN_Word2Vec_model architecture\n",
        "\n",
        "plot_model(CNN_Word2Vec_model, to_file='CNN_Word2Vec_model_plot.png', show_shapes=True, show_layer_names=True)\n",
        "Image(retina=True, filename=CNN_Word2Vec_model_plot.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wPPdjq3Wj1hF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "CNN_Word2Vec_model_fit = CNN_Word2Vec_model.fit(X_train, y_train, batch_size=batch_size2, epochs=num_epochs, validation_split=val_split, callbacks=[early])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k8vAeqffj4R8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "CNN_Word2Vec_train_score = CNN_Word2Vec_model.evaluate(X_train, y_train, batch_size=batch_size2, verbose=1)\n",
        "print('Train Loss:', CNN_Word2Vec_train_score[0])\n",
        "print('Train Accuracy:', CNN_Word2Vec_train_score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q733bGk7j6wf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "CNN_Word2Vec_test_score = CNN_Word2Vec_model.evaluate(X_test, y_test, batch_size=batch_size2, verbose=1)\n",
        "print('Test Loss:', CNN_Word2Vec_test_score[0])\n",
        "print('Test Accuracy:', CNN_Word2Vec_test_score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A_S65elrj9nt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Predicting......\n",
        "print('Predicting....')\n",
        "y_pred = CNN_Word2Vec_model.predict(X_test,batch_size=batch_size2,verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7ZwqACJEkBal",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Plot training & validation accuracy values\n",
        "plt.plot(CNN_Word2Vec_model_fit.history['acc'])\n",
        "plt.plot(CNN_Word2Vec_model_fit.history['val_acc'])\n",
        "plt.title('CNN-Word2Vec Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training Accuracy', 'Validation Accuracy'], loc='upper left')\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0K4SBNuHkHbE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Plot training & validation loss values\n",
        "plt.plot(CNN_Word2Vec_model_fit.history['loss'])\n",
        "plt.plot(CNN_Word2Vec_model_fit.history['val_loss'])\n",
        "plt.title('CNN-Word2Vec Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training Loss', 'Validation Loss'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JVrSxJL4kMGO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 7) Recurrent Neural Network (RNN) with Word2Vec"
      ]
    },
    {
      "metadata": {
        "id": "ZT3M69FVkRKr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "RNN_Word2Vec_model = Sequential([\n",
        "    Embedding(input_dim =embedding_matrix.shape[0], input_length=max_len, output_dim=embedding_matrix.shape[1],weights=[embedding_matrix], trainable=False),\n",
        "    SpatialDropout1D(0.5),\n",
        "    #Bidirectional layer will enable our model to predict a missing word in a sequence, \n",
        "    #So, using this feature will enable the model to look at the context on both the left and the right.\n",
        "    Bidirectional(LSTM(25, return_sequences=True)),\n",
        "    #**batch normalization layer** normalizes the activations of the previous layer at each batch, \n",
        "    #i.e. applies a transformation that maintains the mean activation close to 0 and the activation standard deviation close to 1. \n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    GlobalMaxPool1D(),\n",
        "    Dense(50, activation = 'relu'),\n",
        "    Dense(6, activation = 'sigmoid')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eVEfBpTikW83",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Customized the evaluation to analyse the model in terms of accuracy and mean value accuracy\n",
        "def mean_pred(y_true, y_pred):\n",
        "    return K.mean(y_pred)\n",
        "\n",
        "RNN_Word2Vec_model.compile(loss='binary_crossentropy', optimizer=Adam(0.01), metrics=['accuracy', mean_pred])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "flnM-ghykYEw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "RNN_Word2Vec_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qi9EK0MVwW5a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#plot the RNN_Word2Vec_model architecture\n",
        "\n",
        "plot_model(RNN_Word2Vec_model, to_file='RNN_Word2Vec_model_plot.png', show_shapes=True, show_layer_names=True)\n",
        "Image(retina=True, filename=RNN_Word2Vec_model_plot.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2GALxf3TkaiD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "RNN_Word2Vec_model_fit = RNN_Word2Vec_model.fit(X_train, y_train, batch_size=batch_size2, epochs=num_epochs, validation_split=val_split, callbacks=[early])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uh28E29zkdiN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "RNN_Word2Vec_train_score = RNN_Word2Vec_model.evaluate(X_train, y_train, batch_size=batch_size2, verbose=1)\n",
        "print('Train Loss:', RNN_Word2Vec_train_score[0])\n",
        "print('Train Accuracy:', RNN_Word2Vec_train_score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GLgq6Bsnko_S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "RNN_Word2Vec_test_score = RNN_Word2Vec_model.evaluate(X_test, y_test, batch_size=batch_size2, verbose=1)\n",
        "print('Test Loss:', RNN_Word2Vec_test_score[0])\n",
        "print('Test Accuracy:', RNN_Word2Vec_test_score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "buWNvKc3krrk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Predicting......\n",
        "print('Predicting....')\n",
        "y_pred = RNN_Word2Vec_model.predict(X_test,batch_size=batch_size2,verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gUE8UHRMks0K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Plot training & validation accuracy values\n",
        "plt.plot(RNN_Word2Vec_model_fit.history['acc'])\n",
        "plt.plot(RNN_Word2Vec_model_fit.history['val_acc'])\n",
        "plt.title('RNN-Word2Vec Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training Accuracy', 'Validation Accuracy'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dWKszgsNkytT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Plot training & validation loss values\n",
        "plt.plot(RNN_Word2Vec_model_fit.history['loss'])\n",
        "plt.plot(RNN_Word2Vec_model_fit.history['val_loss'])\n",
        "plt.title('RNN-Word2Vec Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training Loss', 'Validation Loss'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kVRmORRCk0oo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## C) \"FasText\" as a pre-trained Embedding"
      ]
    },
    {
      "metadata": {
        "id": "p6uvH0FWk9c8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Load the FastText Word Embeddng Corpus"
      ]
    },
    {
      "metadata": {
        "id": "17wOZeDvk69T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#load embeddings\n",
        "print('loading word embeddings...')\n",
        "fastText_embeddings_index = {}\n",
        "f = codecs.open('wiki.simple.vec', encoding='utf-8')\n",
        "for line in tqdm(f):\n",
        "    values = line.rstrip().rsplit(' ')\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    fastText_embeddings_index[word] = coefs\n",
        "f.close()\n",
        "print('found %s word vectors' % len(fastText_embeddings_index))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TC2IG4kYlDOl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#embedding matrix\n",
        "print('preparing embedding matrix...')\n",
        "words_not_found = []\n",
        "nb_words = min(MAX_NB_WORDS, len(word_index))\n",
        "fastText_embedding_matrix = np.zeros((nb_words, embed_dim))\n",
        "for word, i in word_index.items():\n",
        "    if i >= nb_words:\n",
        "        continue\n",
        "    fastText_embedding_vector = fastText_embeddings_index.get(word)\n",
        "    if (fastText_embedding_vector is not None) and len(fastText_embedding_vector) > 0:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        fastText_embedding_matrix[i] = fastText_embedding_vector\n",
        "    else:\n",
        "        words_not_found.append(word)\n",
        "print('number of null word embeddings: %d' % np.sum(np.sum(fastText_embedding_matrix, axis=1) == 0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BTgGQVyylKX1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(nb_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9N5twJkalIbI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 8) Convolutional Neural Network (CNN) with FastText"
      ]
    },
    {
      "metadata": {
        "id": "ZmB4r7FblRqG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "CNN_FastText_model = Sequential([\n",
        "    Embedding(input_dim=fastText_embedding_matrix.shape[0], input_length=max_len, output_dim=fastText_embedding_matrix.shape[1],weights=[fastText_embedding_matrix], trainable=False),\n",
        "    SpatialDropout1D(0.5),\n",
        "    # ... 100 filters with a kernel size of 4 so that each convolution will consider a window of 4 word embeddings\n",
        "    Conv1D(filters=100, kernel_size=4, padding='same', activation='relu'),\n",
        "    #**batch normalization layer** normalizes the activations of the previous layer at each batch, \n",
        "    #i.e. applies a transformation that maintains the mean activation close to 0 and the activation standard deviation close to 1. \n",
        "    #It will be added after the activation function between a convolutional and a max-pooling layer.\n",
        "    BatchNormalization(),\n",
        "    GlobalMaxPool1D(),\n",
        "    Dropout(0.5),\n",
        "    Dense(50, activation = 'relu'),\n",
        "    Dense(6, activation = 'sigmoid')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zuKSOTHmlUl-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Customized the evaluation to analyse the model in terms of accuracy and mean value accuracy\n",
        "def mean_pred(y_true, y_pred):\n",
        "    return K.mean(y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PopT5igalWC6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "CNN_FastText_model.compile(loss='binary_crossentropy', optimizer=Adam(0.01), metrics=['accuracy', mean_pred])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hO836PbUlagW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "CNN_FastText_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EokmYDzYw_Qs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#plot the CNN_FastText_model architecture\n",
        "\n",
        "plot_model(CNN_FastText_model, to_file='CNN_FastText_model_plot.png', show_shapes=True, show_layer_names=True)\n",
        "Image(retina=True, filename=CNN_FastText_model_plot.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9AWfMlUSldXp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "CNN_FastText_model_fit = CNN_FastText_model.fit(X_train, y_train, batch_size=batch_size2, epochs=num_epochs, validation_split=val_split, callbacks=[early])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8MP6iO-3lgBe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "CNN_FastText_train_score = CNN_FastText_model.evaluate(X_train, y_train, batch_size=batch_size2, verbose=1)\n",
        "print('Train Loss:', CNN_FastText_train_score[0])\n",
        "print('Train Accuracy:', CNN_FastText_train_score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wF-E-YfXlifj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "CNN_FastText_test_score = CNN_FastText_model.evaluate(X_test, y_test, batch_size=batch_size2, verbose=1)\n",
        "print('Test Loss:', CNN_FastText_train_score[0])\n",
        "print('Test Accuracy:', CNN_FastText_train_score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hosf_OzalksO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Predicting......\n",
        "print('Predicting....')\n",
        "y_pred = CNN_FastText_model.predict(X_test,batch_size=batch_size2,verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nNQYtI4LloSs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Plot training & validation accuracy values\n",
        "plt.plot(CNN_FastText_model_fit.history['acc'])\n",
        "plt.plot(CNN_FastText_model_fit.history['val_acc'])\n",
        "plt.title('CNN-FastText Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training Accuracy', 'Validation Accuracy'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u4TIrrZNlp2Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Plot training & validation loss values\n",
        "plt.plot(CNN_FastText_model_fit.history['loss'])\n",
        "plt.plot(CNN_FastText_model_fit.history['val_loss'])\n",
        "plt.title('CNN-FastText Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training Loss', 'Validation Loss'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q9LGffb2l7JW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 9) Recurrent Neural Network (RNN) with FastText"
      ]
    },
    {
      "metadata": {
        "id": "WeuwCt6Jl93r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "RNN_FastText_model = Sequential([\n",
        "    Embedding(input_dim =fastText_embedding_matrix.shape[0], input_length=max_len, output_dim=fastText_embedding_matrix.shape[1],weights=[fastText_embedding_matrix], trainable=False),\n",
        "    SpatialDropout1D(0.5),\n",
        "    #Bidirectional layer will enable our model to predict a missing word in a sequence, \n",
        "    #So, using this feature will enable the model to look at the context on both the left and the right.\n",
        "    Bidirectional(LSTM(25, return_sequences=True)),\n",
        "    #**batch normalization layer** normalizes the activations of the previous layer at each batch, \n",
        "    #i.e. applies a transformation that maintains the mean activation close to 0 and the activation standard deviation close to 1. \n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    GlobalMaxPool1D(),\n",
        "    Dense(50, activation = 'relu'),\n",
        "    Dense(6, activation = 'sigmoid')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tamCBt2emBZq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Customized the evaluation to analyse the model in terms of accuracy and mean value accuracy\n",
        "def mean_pred(y_true, y_pred):\n",
        "    return K.mean(y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j9SFCjfNmEyi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "RNN_FastText_model.compile(loss='binary_crossentropy', optimizer=Adam(0.01), metrics=['accuracy', mean_pred])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tmrQckJBmHp5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "RNN_FastText_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vsKSacORxYkA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#plot the RNN_FastText_model architecture\n",
        "\n",
        "plot_model(RNN_FastText_model, to_file='RNN_FastText_model_plot.png', show_shapes=True, show_layer_names=True)\n",
        "Image(retina=True, filename=RNN_FastText_model_plot.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gtxDXykXmKXY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "RNN_FastText_model_fit = RNN_FastText_model.fit(X_train, y_train, batch_size=batch_size2, epochs=num_epochs, validation_split=val_split, callbacks=[early])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wh1TsqbcmM29",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "RNN_FastText_train_score = RNN_FastText_model.evaluate(X_train, y_train, batch_size=batch_size2, verbose=1)\n",
        "print('Train Loss:', RNN_FastText_train_score[0])\n",
        "print('Train Accuracy:', RNN_FastText_train_score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3W0b4Zb_mPeC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "RNN_FastText_test_score = RNN_FastText_model.evaluate(X_test, y_test, batch_size=batch_size2, verbose=1)\n",
        "print('Test Loss:', RNN_FastText_test_score[0])\n",
        "print('Test Accuracy:', RNN_FastText_test_score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CiyCdGSVmSXL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Predicting......\n",
        "print('Predicting....')\n",
        "y_pred = RNN_FastText_model.predict(X_test,batch_size=batch_size2,verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2o5qqWHvmVIE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Plot training & validation accuracy values\n",
        "plt.plot(RNN_FastText_model_fit.history['acc'])\n",
        "plt.plot(RNN_FastText_model_fit.history['val_acc'])\n",
        "plt.title('CNN-FastText Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training Accuracy', 'Validation Accuracy'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OWdqH-PqmWZJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Plot training & validation loss values\n",
        "plt.plot(RNN_FastText_model_fit.history['loss'])\n",
        "plt.plot(RNN_FastText_model_fit.history['val_loss'])\n",
        "plt.title('CNN-FastText Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training Loss', 'Validation Loss'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "db28Tpnvejiq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### EVALUATION"
      ]
    },
    {
      "metadata": {
        "id": "v8fXF_dmejiq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# concat all training, validation and testing accuracy scores\n",
        "NN_Accuracy = ['Neural Network', \n",
        "               np.mean(nn_model_fit.history['acc']), \n",
        "               np.mean(nn_model_fit.history['val_acc']), \n",
        "               nn_test_score[1]]\n",
        "\n",
        "CNN_Accuracy = ['Convolutional Neural Network (CNN)', \n",
        "                np.mean(CNN_model_fit.history['acc']), \n",
        "                np.mean(CNN_model_fit.history['val_acc']), \n",
        "                CNN_test_score[1]]\n",
        "\n",
        "RNN_Accuracy = ['Recurrent Neural Networks (RNNs)', \n",
        "                np.mean(RNN_model_fit.history['acc']), \n",
        "                np.mean(RNN_model_fit.history['val_acc']), \n",
        "                RNN_test_score[1]]\n",
        "\n",
        "CNN_Glove_Accuracy = ['Convolutional Neural Network (CNN) with Glove', \n",
        "                  np.mean(CNN_Glove_model_fit.history['acc']), \n",
        "                  np.mean(CNN_Glove_model_fit.history['val_acc']), \n",
        "                  CNN_Glove_test_score[1]]\n",
        "\n",
        "RNN_Glove_Accuracy = ['Recurrent Neural Networks (RNNs) with Glove', \n",
        "                    np.mean(RNN_Glove_model_fit.history['acc']), \n",
        "                    np.mean(RNN_Glove_model_fit.history['val_acc']), \n",
        "                    RNN_Glove_test_score[1]]\n",
        "\n",
        "CNN_Word2Vec_Accuracy = ['Convolutional Neural Networks (CNNs) with Word2Vec', \n",
        "                    np.mean(CNN_Word2Vec_model_fit.history['acc']), \n",
        "                    np.mean(CNN_Word2Vec_model_fit.history['val_acc']), \n",
        "                    CNN_Word2Vec_test_score[1]]\n",
        "\n",
        "RNN_Word2Vec_Accuracy = ['Recurrent Neural Networks (RNNs) with Word2Vec', \n",
        "                    np.mean(RNN_Word2Vec_model_fit.history['acc']), \n",
        "                    np.mean(RNN_Word2Vec_model_fit.history['val_acc']), \n",
        "                    RNN_Word2Vec_test_score[1]]\n",
        "\n",
        "CNN_FastText_Accuracy = ['Convolutional Neural Networks (RNNs) with FastText', \n",
        "                    np.mean(RNN_FastText_model_fit.history['acc']), \n",
        "                    np.mean(RNN_FastText_model_fit.history['val_acc']), \n",
        "                    RNN_Word2Vec_test_score[1]]\n",
        "\n",
        "\n",
        "RNN_FastText_Accuracy = ['Recurrent Neural Networks (RNNs) with FastText', \n",
        "                    np.mean(RNN_Word2Vec_model_fit.history['acc']), \n",
        "                    np.mean(RNN_Word2Vec_model_fit.history['val_acc']), \n",
        "                    RNN_Word2Vec_test_score[1]]\n",
        "\n",
        "\n",
        "# create dataframe\n",
        "comparison = pd.DataFrame([NN_Accuracy])\n",
        "# append all other scores\n",
        "comparison = comparison.append([CNN_Accuracy, RNN_Accuracy, CNN_Glove_Accuracy, RNN_Glove_Accuracy, CNN_Word2Vec_Accuracy, \n",
        "                                RNN_Word2Vec_Accuracy, CNN_FastText_Accuracy, RNN_FastText_Accuracy])\n",
        "\n",
        "\n",
        "# beautify the new dataframe\n",
        "comparison.columns = ['Model', 'Training Accuracy', 'Validation Accuracy', 'Testing Accuracy']\n",
        "comparison.set_index(['Model'], inplace=True)\n",
        "comparison\n",
        "print(comparison)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d5CoWpDuZlDM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### FASTEXT"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4X48x-U2ZzBD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### FASTEXT\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"Let's load the data and the embeddings...\"\"\"\n",
        "\n",
        "#load embeddings\n",
        "print('loading word embeddings...')\n",
        "embeddings_index = {}\n",
        "f = codecs.open('wiki.simple.vec', encoding='utf-8')\n",
        "for line in tqdm(f):\n",
        "    values = line.rstrip().rsplit(' ')\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "print('found %s word vectors' % len(embeddings_index))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8cDdRmvQurBk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##NOTE: Change the train and test tokenizer\n",
        "\n",
        "\n",
        "print(\"tokenizing input data...\")\n",
        "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, lower=True, char_level=False)\n",
        "tokenizer.fit_on_texts(processed_docs_train + processed_docs_test)  #leaky\n",
        "word_seq_train = tokenizer.texts_to_sequences(processed_docs_train)\n",
        "word_seq_test = tokenizer.texts_to_sequences(processed_docs_test)\n",
        "word_index = tokenizer.word_index\n",
        "word_index = tokenizer.word_index\n",
        "print(\"dictionary size: \", len(word_index))\n",
        "#embedding matrix\n",
        "print('preparing embedding matrix...')\n",
        "words_not_found = []\n",
        "nb_words = min(MAX_NB_WORDS, len(word_index))\n",
        "embedding_matrix = np.zeros((nb_words, embed_dim))\n",
        "for word, i in word_index.items():\n",
        "    if i >= nb_words:\n",
        "        continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if (embedding_vector is not None) and len(embedding_vector) > 0:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "    else:\n",
        "        words_not_found.append(word)\n",
        "print('number of null word embeddings: %d' % np.sum(np.sum(embedding_matrix, axis=1) == 0))\n",
        "\n",
        "\"\"\"It's interesting to look at the words not found in the embeddings:\"\"\"\n",
        "\n",
        "print(\"sample words not found: \", np.random.choice(words_not_found, 10))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T-5hs4s0HV06",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XX0S55o2ZuLb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "lHnKMNGXiRSK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}